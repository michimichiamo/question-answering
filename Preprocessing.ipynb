{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c69e289",
   "metadata": {
    "id": "3c69e289"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291d7474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T16:50:12.141547Z",
     "start_time": "2022-02-02T16:50:11.518239Z"
    },
    "id": "291d7474"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Suppress output\n",
    "\n",
    "# Whether the notebook is run within Google Colab or not\n",
    "colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Install needed dependencies on Colab\n",
    "if colab:\n",
    "    !pip install transformers\n",
    "\n",
    "# Automatically reimport modules at each execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "xNvyQ4HhHCOM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNvyQ4HhHCOM",
    "outputId": "9d2c54ae-e45d-482f-a624-1bc566f5d8eb"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !git clone https://github.com/michimichiamo/question-answering\n",
    "    %cd '/content/question-answering'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5306980",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c77297",
   "metadata": {
    "hidden": true,
    "id": "82c77297"
   },
   "source": [
    "## Convert JSON to CSV format\n",
    "\n",
    "- Load nested JSON into linearized `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862509a4",
   "metadata": {
    "hidden": true,
    "id": "862509a4"
   },
   "outputs": [],
   "source": [
    "from util.preprocessing import read_from_json\n",
    "\n",
    "df = read_from_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ace68",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01476579",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv('./data/raw/df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ce2b2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Split training/validation\n",
    "\n",
    "- Split based on titles, following the suggestion:\n",
    "> all the questions/paragraphs regarding the same title should be in the same split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aed803c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split on titles\n",
    "titles = df['title'].unique()\n",
    "train_titles, val_titles = train_test_split(titles, test_size=0.2, shuffle=True, random_state=42)\n",
    "# Extract DataFrames\n",
    "train_df = df[df.apply(lambda x: x['title'] in train_titles, axis=1)]\n",
    "val_df = df[df.apply(lambda x: x['title'] in val_titles, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2397e3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd2d59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train_df.to_csv('./data/raw/train_df.csv')\n",
    "#val_df.to_csv('./data/raw/val_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa58304",
   "metadata": {
    "hidden": true,
    "id": "eaa58304"
   },
   "source": [
    "## Read data\n",
    "\n",
    "- Load data from saved `.csv` files\n",
    "- `keep_default_na=False` is needed as to avoid interpreting as `nan` an answer reporting `'null'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a453903",
   "metadata": {
    "hidden": true,
    "id": "8a453903"
   },
   "outputs": [],
   "source": [
    "directory = './data/raw/'\n",
    "train_filename = directory+'train_df.csv'\n",
    "val_filename = directory+'val_df.csv'\n",
    "train_df = pd.read_csv(train_filename, index_col=0, keep_default_na=False)\n",
    "val_df = pd.read_csv(val_filename, index_col=0, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b51061",
   "metadata": {
    "hidden": true,
    "id": "46b51061"
   },
   "source": [
    "## Tokenize questions and contexts\n",
    "\n",
    "- Use of `transformers.DistilBertTokenizerFast` to obtain tokenized questions and contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7919d845",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n",
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from util.preprocessing import tokenize\n",
    "\n",
    "train_df = tokenize(train_df)\n",
    "val_df = tokenize(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb199b2d",
   "metadata": {
    "hidden": true,
    "id": "eb199b2d"
   },
   "source": [
    "## Fix answers' position\n",
    "\n",
    "Answers are provided in the form of (char_start, char_end) with respect to the original context, however:\n",
    "- After tokenization, **characters** have no meaning anymore, since we deal with words\n",
    "  - Thus, we convert characters to **word indices**\n",
    "- Tokenization splits long contexts (according to the parameter `max_length`), which results in some context splits not containing the answer.\n",
    "  - To address this problem, we assign `answer_start, answer_end = (0,0)` whenever the answer is neither partially nor fully contained within the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632c7a22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from util.preprocessing import fix_answers\n",
    "\n",
    "fix_answers(train_df)\n",
    "fix_answers(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbc431",
   "metadata": {
    "hidden": true,
    "id": "0efbc431"
   },
   "source": [
    "## Save\n",
    "\n",
    "- Allow for one-hot encoding of answers (which however seems not useful, as both the loss function (`torch.CrossEntropyLoss`) and the evaluation metrics (`torchmetrics.F1Score`, `torchmetrics.Accuracy`, `torchmetrics.AveragePrecision`) accept targets as 1D.\n",
    "- Save data as a compressed `.npz` archive for later retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fnTP7V3LFuHn",
   "metadata": {
    "hidden": true,
    "id": "fnTP7V3LFuHn"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for answers\n",
    "one_hot = False\n",
    "if one_hot:\n",
    "    from util.preprocessing import one_hot_answers\n",
    "    oh_data = one_hot_answers(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26f91e65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save integer data\n",
    "keys = ['input_ids', 'attention_mask', 'answer_start', 'answer_end']\n",
    "train_data = {key:np.stack(train_df[key]).astype('int32') for key in keys}\n",
    "val_data = {key:np.stack(val_df[key]).astype('int32') for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "817ff1b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save id (string)\n",
    "train_data['id'] = train_df['id'].values.astype(np.unicode_)\n",
    "val_data['id'] = val_df['id'].values.astype(np.unicode_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f8386d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./data/tokenized/train.npz', **train_data)\n",
    "np.savez_compressed('./data/tokenized/val.npz', **val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f0c94",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Sanity check\n",
    "\n",
    "- Check data was correctly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b01dcd84",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data_saved = np.load('./data/tokenized/train.npz')\n",
    "val_data_saved = np.load('./data/tokenized/val.npz')\n",
    "\n",
    "for key in keys:\n",
    "    assert np.equal(train_data[key], train_data_saved[key]).all()\n",
    "    assert np.equal(val_data[key], val_data_saved[key]).all()\n",
    "    \n",
    "assert (np.char.strip(train_data['id']) == np.char.strip(train_data_saved['id'])).all()\n",
    "assert (np.char.strip(val_data['id']) == np.char.strip(val_data_saved['id'])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c9c8e",
   "metadata": {},
   "source": [
    "# Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f333e5",
   "metadata": {
    "id": "eaa58304"
   },
   "source": [
    "## Read data\n",
    "\n",
    "- Load data from saved `.csv` files\n",
    "- `keep_default_na=False` is needed as to avoid interpreting as `nan` an answer reporting `'null'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4d63d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T16:59:37.973865Z",
     "start_time": "2022-02-02T16:59:36.839839Z"
    },
    "id": "8a453903"
   },
   "outputs": [],
   "source": [
    "directory = './data/raw/'\n",
    "train_filename = directory+'train_df.csv'\n",
    "val_filename = directory+'val_df.csv'\n",
    "train_df = pd.read_csv(train_filename, index_col=0, keep_default_na=False)\n",
    "val_df = pd.read_csv(val_filename, index_col=0, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4c475",
   "metadata": {},
   "source": [
    "### Drop duplicates\n",
    "\n",
    "- Keep only one question for each context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2053d6d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T16:59:39.119594Z",
     "start_time": "2022-02-02T16:59:38.941559Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop_duplicates(['context'], inplace=True)\n",
    "val_df.drop_duplicates(['context'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f64b37",
   "metadata": {
    "id": "46b51061"
   },
   "source": [
    "## Tokenize questions and contexts\n",
    "\n",
    "- Use of `transformers.T5TokenizerFast` to obtain tokenized questions and contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94c34343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:00:15.268434Z",
     "start_time": "2022-02-02T16:59:40.741362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n",
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from util.preprocessing_qg import tokenize\n",
    "\n",
    "train_df = tokenize(train_df)\n",
    "val_df = tokenize(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377684d3",
   "metadata": {
    "id": "eb199b2d"
   },
   "source": [
    "## Fix answers' position\n",
    "\n",
    "Answers are provided in the form of (char_start, char_end) with respect to the original context, however:\n",
    "- After tokenization, **characters** have no meaning anymore, since we deal with words\n",
    "  - Thus, we convert characters to **word indices**\n",
    "- Tokenization splits long contexts (according to the parameter `max_length`), which results in some context splits not containing the answer.\n",
    "  - To address this problem, we assign `answer_start, answer_end = (0,0)` whenever the answer is neither partially nor fully contained within the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40a5663c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:00:19.104701Z",
     "start_time": "2022-02-02T17:00:17.487132Z"
    }
   },
   "outputs": [],
   "source": [
    "from util.preprocessing_qg import fix_answers\n",
    "\n",
    "fix_answers(train_df)\n",
    "fix_answers(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea6765",
   "metadata": {},
   "source": [
    "## Clear 0s\n",
    "\n",
    "- Eliminate samples for which answers are not included in the context\n",
    "- This is needed to ensure at least a target for each context when it comes to generated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18f44da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:00:21.257857Z",
     "start_time": "2022-02-02T17:00:21.170058Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df[~((train_df['answer_start'] == 0) & (train_df['answer_end'] == 0))]\n",
    "val_df = val_df[~((val_df['answer_start'] == 0) & (val_df['answer_end'] == 0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899bbc4",
   "metadata": {
    "id": "0efbc431"
   },
   "source": [
    "## Save\n",
    "\n",
    "- Allow for one-hot encoding of answers (which however seems not useful, as both the loss function (`torch.CrossEntropyLoss`) and the evaluation metrics (`torchmetrics.F1Score`, `torchmetrics.Accuracy`, `torchmetrics.AveragePrecision`) accept targets as 1D.\n",
    "- Save data as a compressed `.npz` archive for later retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46edfb4",
   "metadata": {
    "id": "fnTP7V3LFuHn"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for answers\n",
    "one_hot = False\n",
    "if one_hot:\n",
    "    from util.preprocessing import one_hot_answers\n",
    "    oh_data = one_hot_answers(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1296b2db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:00:36.232154Z",
     "start_time": "2022-02-02T17:00:24.461193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save integer data\n",
    "keys = [item for item in list(train_df.columns) if item != 'id']\n",
    "train_data = {key:np.stack(train_df[key]).astype('int32') for key in keys}\n",
    "val_data = {key:np.stack(val_df[key]).astype('int32') for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e353a50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:00:37.359203Z",
     "start_time": "2022-02-02T17:00:37.298114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save id (string)\n",
    "train_data['id'] = train_df['id'].values.astype(np.unicode_)\n",
    "val_data['id'] = val_df['id'].values.astype(np.unicode_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "957822c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:00:44.097095Z",
     "start_time": "2022-02-02T17:00:39.648844Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./data/tokenized-qg/train.npz', **train_data)\n",
    "np.savez_compressed('./data/tokenized-qg/val.npz', **val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e433a4",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "\n",
    "- Check data was correctly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f327aa80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-02T17:00:48.555932Z",
     "start_time": "2022-02-02T17:00:47.323364Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_saved = np.load('./data/tokenized-qg/train.npz')\n",
    "val_data_saved = np.load('./data/tokenized-qg/val.npz')\n",
    "\n",
    "for key in keys:\n",
    "    assert np.equal(train_data[key], train_data_saved[key]).all()\n",
    "    assert np.equal(val_data[key], val_data_saved[key]).all()\n",
    "    \n",
    "assert (np.char.strip(train_data['id']) == np.char.strip(train_data_saved['id'])).all()\n",
    "assert (np.char.strip(val_data['id']) == np.char.strip(val_data_saved['id'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba8ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "QA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
