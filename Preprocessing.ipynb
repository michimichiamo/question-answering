{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c69e289",
   "metadata": {
    "id": "3c69e289"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291d7474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:17:50.202920Z",
     "start_time": "2022-02-01T17:17:48.940798Z"
    },
    "id": "291d7474"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Suppress output\n",
    "\n",
    "# Whether the notebook is run within Google Colab or not\n",
    "colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Install needed dependencies on Colab\n",
    "if colab:\n",
    "    !pip install transformers\n",
    "\n",
    "# Automatically reimport modules at each execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "xNvyQ4HhHCOM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNvyQ4HhHCOM",
    "outputId": "9d2c54ae-e45d-482f-a624-1bc566f5d8eb"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !git clone https://github.com/michimichiamo/question-answering\n",
    "    %cd '/content/question-answering'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e0a6c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c77297",
   "metadata": {
    "hidden": true,
    "id": "82c77297"
   },
   "source": [
    "## Convert JSON to CSV format\n",
    "\n",
    "- Load nested JSON into linearized `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862509a4",
   "metadata": {
    "hidden": true,
    "id": "862509a4"
   },
   "outputs": [],
   "source": [
    "from util.preprocessing import read_from_json\n",
    "\n",
    "df = read_from_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ace68",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01476579",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv('./data/raw/df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ce2b2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Split training/validation\n",
    "\n",
    "- Split based on titles, following the suggestion:\n",
    "> all the questions/paragraphs regarding the same title should be in the same split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aed803c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split on titles\n",
    "titles = df['title'].unique()\n",
    "train_titles, val_titles = train_test_split(titles, test_size=0.2, shuffle=True, random_state=42)\n",
    "# Extract DataFrames\n",
    "train_df = df[df.apply(lambda x: x['title'] in train_titles, axis=1)]\n",
    "val_df = df[df.apply(lambda x: x['title'] in val_titles, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2397e3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd2d59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train_df.to_csv('./data/raw/train_df.csv')\n",
    "#val_df.to_csv('./data/raw/val_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa58304",
   "metadata": {
    "hidden": true,
    "id": "eaa58304"
   },
   "source": [
    "## Read data\n",
    "\n",
    "- Load data from saved `.csv` files\n",
    "- `keep_default_na=False` is needed as to avoid interpreting as `nan` an answer reporting `'null'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a453903",
   "metadata": {
    "hidden": true,
    "id": "8a453903"
   },
   "outputs": [],
   "source": [
    "directory = './data/raw/'\n",
    "train_filename = directory+'train_df.csv'\n",
    "val_filename = directory+'val_df.csv'\n",
    "train_df = pd.read_csv(train_filename, index_col=0, keep_default_na=False)\n",
    "val_df = pd.read_csv(val_filename, index_col=0, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b51061",
   "metadata": {
    "hidden": true,
    "id": "46b51061"
   },
   "source": [
    "## Tokenize questions and contexts\n",
    "\n",
    "- Use of `transformers.DistilBertTokenizerFast` to obtain tokenized questions and contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7919d845",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n",
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from util.preprocessing import tokenize\n",
    "\n",
    "train_df = tokenize(train_df)\n",
    "val_df = tokenize(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb199b2d",
   "metadata": {
    "hidden": true,
    "id": "eb199b2d"
   },
   "source": [
    "## Fix answers' position\n",
    "\n",
    "Answers are provided in the form of (char_start, char_end) with respect to the original context, however:\n",
    "- After tokenization, **characters** have no meaning anymore, since we deal with words\n",
    "  - Thus, we convert characters to **word indices**\n",
    "- Tokenization splits long contexts (according to the parameter `max_length`), which results in some context splits not containing the answer.\n",
    "  - To address this problem, we assign `answer_start, answer_end = (0,0)` whenever the answer is neither partially nor fully contained within the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632c7a22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from util.preprocessing import fix_answers\n",
    "\n",
    "fix_answers(train_df)\n",
    "fix_answers(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbc431",
   "metadata": {
    "hidden": true,
    "id": "0efbc431"
   },
   "source": [
    "## Save\n",
    "\n",
    "- Allow for one-hot encoding of answers (which however seems not useful, as both the loss function (`torch.CrossEntropyLoss`) and the evaluation metrics (`torchmetrics.F1Score`, `torchmetrics.Accuracy`, `torchmetrics.AveragePrecision`) accept targets as 1D.\n",
    "- Save data as a compressed `.npz` archive for later retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fnTP7V3LFuHn",
   "metadata": {
    "hidden": true,
    "id": "fnTP7V3LFuHn"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for answers\n",
    "one_hot = False\n",
    "if one_hot:\n",
    "    from util.preprocessing import one_hot_answers\n",
    "    oh_data = one_hot_answers(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26f91e65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save integer data\n",
    "keys = ['input_ids', 'attention_mask', 'answer_start', 'answer_end']\n",
    "train_data = {key:np.stack(train_df[key]).astype('int32') for key in keys}\n",
    "val_data = {key:np.stack(val_df[key]).astype('int32') for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "817ff1b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save id (string)\n",
    "train_data['id'] = train_df['id'].values.astype(np.unicode_)\n",
    "val_data['id'] = val_df['id'].values.astype(np.unicode_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f8386d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./data/tokenized/train.npz', **train_data)\n",
    "np.savez_compressed('./data/tokenized/val.npz', **val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f0c94",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Sanity check\n",
    "\n",
    "- Check data was correctly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b01dcd84",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data_saved = np.load('./data/tokenized/train.npz')\n",
    "val_data_saved = np.load('./data/tokenized/val.npz')\n",
    "\n",
    "for key in keys:\n",
    "    assert np.equal(train_data[key], train_data_saved[key]).all()\n",
    "    assert np.equal(val_data[key], val_data_saved[key]).all()\n",
    "    \n",
    "assert (np.char.strip(train_data['id']) == np.char.strip(train_data_saved['id'])).all()\n",
    "assert (np.char.strip(val_data['id']) == np.char.strip(val_data_saved['id'])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb1603",
   "metadata": {},
   "source": [
    "# Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233dd280",
   "metadata": {
    "id": "eaa58304"
   },
   "source": [
    "## Read data\n",
    "\n",
    "- Load data from saved `.csv` files\n",
    "- `keep_default_na=False` is needed as to avoid interpreting as `nan` an answer reporting `'null'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c7b75f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:17:57.727468Z",
     "start_time": "2022-02-01T17:17:56.876679Z"
    },
    "id": "8a453903"
   },
   "outputs": [],
   "source": [
    "directory = './data/raw/'\n",
    "train_filename = directory+'train_df.csv'\n",
    "val_filename = directory+'val_df.csv'\n",
    "train_df = pd.read_csv(train_filename, index_col=0, keep_default_na=False)\n",
    "val_df = pd.read_csv(val_filename, index_col=0, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63299c48",
   "metadata": {
    "id": "46b51061"
   },
   "source": [
    "## Tokenize questions and contexts\n",
    "\n",
    "- Use of `transformers.T5TokenizerFast` to obtain tokenized questions and contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44587c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:20:42.351589Z",
     "start_time": "2022-02-01T17:18:00.700579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n",
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from util.preprocessing_qg import tokenize\n",
    "\n",
    "train_df = tokenize(train_df)\n",
    "val_df = tokenize(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9768b",
   "metadata": {
    "id": "eb199b2d"
   },
   "source": [
    "## Fix answers' position\n",
    "\n",
    "Answers are provided in the form of (char_start, char_end) with respect to the original context, however:\n",
    "- After tokenization, **characters** have no meaning anymore, since we deal with words\n",
    "  - Thus, we convert characters to **word indices**\n",
    "- Tokenization splits long contexts (according to the parameter `max_length`), which results in some context splits not containing the answer.\n",
    "  - To address this problem, we assign `answer_start, answer_end = (0,0)` whenever the answer is neither partially nor fully contained within the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ccaf358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:21:00.747101Z",
     "start_time": "2022-02-01T17:20:44.169701Z"
    }
   },
   "outputs": [],
   "source": [
    "from util.preprocessing_qg import fix_answers\n",
    "\n",
    "fix_answers(train_df)\n",
    "fix_answers(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d9f7e",
   "metadata": {},
   "source": [
    "## Clear 0s\n",
    "\n",
    "- Eliminate samples for which answers are not included in the context\n",
    "- This is needed to ensure at least a target for each context when it comes to generated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c5f0624",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:22:10.553694Z",
     "start_time": "2022-02-01T17:22:10.383282Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df[~((train_df['answer_start'] == 0) & (train_df['answer_end'] == 0))]\n",
    "val_df = val_df[~((val_df['answer_start'] == 0) & (val_df['answer_end'] == 0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f272f2",
   "metadata": {
    "id": "0efbc431"
   },
   "source": [
    "## Save\n",
    "\n",
    "- Allow for one-hot encoding of answers (which however seems not useful, as both the loss function (`torch.CrossEntropyLoss`) and the evaluation metrics (`torchmetrics.F1Score`, `torchmetrics.Accuracy`, `torchmetrics.AveragePrecision`) accept targets as 1D.\n",
    "- Save data as a compressed `.npz` archive for later retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5b750",
   "metadata": {
    "id": "fnTP7V3LFuHn"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for answers\n",
    "one_hot = False\n",
    "if one_hot:\n",
    "    from util.preprocessing import one_hot_answers\n",
    "    oh_data = one_hot_answers(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64720cbe",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-01T17:23:52.344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save integer data\n",
    "keys = [item for item in list(train_df.columns) if item != 'id']\n",
    "train_data = {key:np.stack(train_df[key]).astype('int32') for key in keys}\n",
    "val_data = {key:np.stack(val_df[key]).astype('int32') for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831fa782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save id (string)\n",
    "train_data['id'] = train_df['id'].values.astype(np.unicode_)\n",
    "val_data['id'] = val_df['id'].values.astype(np.unicode_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f2bb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('./data/tokenized-qg/train.npz', **train_data)\n",
    "np.savez_compressed('./data/tokenized-qg/val.npz', **val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c39f36",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "\n",
    "- Check data was correctly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13fb2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_saved = np.load('./data/tokenized-qg/train.npz')\n",
    "val_data_saved = np.load('./data/tokenized-qg/val.npz')\n",
    "\n",
    "for key in keys:\n",
    "    assert np.equal(train_data[key], train_data_saved[key]).all()\n",
    "    assert np.equal(val_data[key], val_data_saved[key]).all()\n",
    "    \n",
    "assert (np.char.strip(train_data['id']) == np.char.strip(train_data_saved['id'])).all()\n",
    "assert (np.char.strip(val_data['id']) == np.char.strip(val_data_saved['id'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf12c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "QA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
