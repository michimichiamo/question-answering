{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c69e289",
   "metadata": {
    "id": "3c69e289"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291d7474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:52:54.855638Z",
     "start_time": "2022-02-01T16:52:53.496736Z"
    },
    "id": "291d7474"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Suppress output\n",
    "\n",
    "# Whether the notebook is run within Google Colab or not\n",
    "colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Install needed dependencies on Colab\n",
    "if colab:\n",
    "    !pip install transformers\n",
    "\n",
    "# Automatically reimport modules at each execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "xNvyQ4HhHCOM",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:52:55.423428Z",
     "start_time": "2022-02-01T16:52:55.398490Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNvyQ4HhHCOM",
    "outputId": "9d2c54ae-e45d-482f-a624-1bc566f5d8eb"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !git clone https://github.com/michimichiamo/question-answering\n",
    "    %cd '/content/question-answering'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ecd7c",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c77297",
   "metadata": {
    "id": "82c77297"
   },
   "source": [
    "## Convert JSON to CSV format\n",
    "\n",
    "- Load nested JSON into linearized `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862509a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:37:03.580911Z",
     "start_time": "2022-01-25T14:36:57.973677Z"
    },
    "id": "862509a4"
   },
   "outputs": [],
   "source": [
    "from util.preprocessing import read_from_json\n",
    "\n",
    "df = read_from_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ace68",
   "metadata": {},
   "source": [
    "### Save DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01476579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('./data/raw/df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ce2b2",
   "metadata": {},
   "source": [
    "## Split training/validation\n",
    "\n",
    "- Split based on titles, following the suggestion:\n",
    "> all the questions/paragraphs regarding the same title should be in the same split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aed803c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:37:09.138953Z",
     "start_time": "2022-01-25T14:37:04.501218Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split on titles\n",
    "titles = df['title'].unique()\n",
    "train_titles, val_titles = train_test_split(titles, test_size=0.2, shuffle=True, random_state=42)\n",
    "# Extract DataFrames\n",
    "train_df = df[df.apply(lambda x: x['title'] in train_titles, axis=1)]\n",
    "val_df = df[df.apply(lambda x: x['title'] in val_titles, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2397e3",
   "metadata": {},
   "source": [
    "### Save DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.to_csv('./data/raw/train_df.csv')\n",
    "#val_df.to_csv('./data/raw/val_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa58304",
   "metadata": {
    "id": "eaa58304"
   },
   "source": [
    "## Read data\n",
    "\n",
    "- Load data from saved `.csv` files\n",
    "- `keep_default_na=False` is needed as to avoid interpreting as `nan` an answer reporting `'null'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a453903",
   "metadata": {
    "id": "8a453903"
   },
   "outputs": [],
   "source": [
    "directory = './data/raw/'\n",
    "train_filename = directory+'train_df.csv'\n",
    "val_filename = directory+'val_df.csv'\n",
    "train_df = pd.read_csv(train_filename, index_col=0, keep_default_na=False)\n",
    "val_df = pd.read_csv(val_filename, index_col=0, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b51061",
   "metadata": {
    "id": "46b51061"
   },
   "source": [
    "## Tokenize questions and contexts\n",
    "\n",
    "- Use of `transformers.DistilBertTokenizerFast` to obtain tokenized questions and contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7919d845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:39:40.055789Z",
     "start_time": "2022-01-25T14:38:42.025204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n",
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from util.preprocessing import tokenize\n",
    "\n",
    "train_df = tokenize(train_df)\n",
    "val_df = tokenize(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb199b2d",
   "metadata": {
    "id": "eb199b2d"
   },
   "source": [
    "## Fix answers' position\n",
    "\n",
    "Answers are provided in the form of (char_start, char_end) with respect to the original context, however:\n",
    "- After tokenization, **characters** have no meaning anymore, since we deal with words\n",
    "  - Thus, we convert characters to **word indices**\n",
    "- Tokenization splits long contexts (according to the parameter `max_length`), which results in some context splits not containing the answer.\n",
    "  - To address this problem, we assign `answer_start, answer_end = (0,0)` whenever the answer is neither partially nor fully contained within the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632c7a22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:40:11.267876Z",
     "start_time": "2022-01-25T14:40:00.247627Z"
    }
   },
   "outputs": [],
   "source": [
    "from util.preprocessing import fix_answers\n",
    "\n",
    "fix_answers(train_df)\n",
    "fix_answers(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbc431",
   "metadata": {
    "id": "0efbc431"
   },
   "source": [
    "## Save\n",
    "\n",
    "- Allow for one-hot encoding of answers (which however seems not useful, as both the loss function (`torch.CrossEntropyLoss`) and the evaluation metrics (`torchmetrics.F1Score`, `torchmetrics.Accuracy`, `torchmetrics.AveragePrecision`) accept targets as 1D.\n",
    "- Save data as a compressed `.npz` archive for later retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fnTP7V3LFuHn",
   "metadata": {
    "id": "fnTP7V3LFuHn"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for answers\n",
    "one_hot = False\n",
    "if one_hot:\n",
    "    from util.preprocessing import one_hot_answers\n",
    "    oh_data = one_hot_answers(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26f91e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T14:51:52.960056Z",
     "start_time": "2022-01-25T14:51:45.311230Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save integer data\n",
    "keys = ['input_ids', 'attention_mask', 'answer_start', 'answer_end']\n",
    "train_data = {key:np.stack(train_df[key]).astype('int32') for key in keys}\n",
    "val_data = {key:np.stack(val_df[key]).astype('int32') for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "817ff1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:00:30.720118Z",
     "start_time": "2022-01-25T15:00:30.653534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save id (string)\n",
    "train_data['id'] = train_df['id'].values.astype(np.unicode_)\n",
    "val_data['id'] = val_df['id'].values.astype(np.unicode_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f8386d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:00:35.130705Z",
     "start_time": "2022-01-25T15:00:31.367283Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./data/tokenized/train.npz', **train_data)\n",
    "np.savez_compressed('./data/tokenized/val.npz', **val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f0c94",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "\n",
    "- Check data was correctly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b01dcd84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T15:02:37.375609Z",
     "start_time": "2022-01-25T15:02:35.053186Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_saved = np.load('./data/tokenized/train.npz')\n",
    "val_data_saved = np.load('./data/tokenized/val.npz')\n",
    "\n",
    "for key in keys:\n",
    "    assert np.equal(train_data[key], train_data_saved[key]).all()\n",
    "    assert np.equal(val_data[key], val_data_saved[key]).all()\n",
    "    \n",
    "assert (np.char.strip(train_data['id']) == np.char.strip(train_data_saved['id'])).all()\n",
    "assert (np.char.strip(val_data['id']) == np.char.strip(val_data_saved['id'])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b8a229",
   "metadata": {},
   "source": [
    "# Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b949e0",
   "metadata": {
    "id": "eaa58304"
   },
   "source": [
    "## Read data\n",
    "\n",
    "- Load data from saved `.csv` files\n",
    "- `keep_default_na=False` is needed as to avoid interpreting as `nan` an answer reporting `'null'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0d2df1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:56:49.057202Z",
     "start_time": "2022-02-01T16:56:48.179857Z"
    },
    "id": "8a453903"
   },
   "outputs": [],
   "source": [
    "directory = './data/raw/'\n",
    "train_filename = directory+'train_df.csv'\n",
    "val_filename = directory+'val_df.csv'\n",
    "train_df = pd.read_csv(train_filename, index_col=0, keep_default_na=False)\n",
    "val_df = pd.read_csv(val_filename, index_col=0, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e52cf7",
   "metadata": {
    "id": "46b51061"
   },
   "source": [
    "## Tokenize questions and contexts\n",
    "\n",
    "- Use of `transformers.DistilBertTokenizerFast` to obtain tokenized questions and contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15997a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:59:31.692681Z",
     "start_time": "2022-02-01T16:57:01.590429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08beda4c4d744ac9ae23a69df27e6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6179e19bf084cab977667199ebe25ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f1051c338248e28045d7de1548b646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n",
      "Loading data...\n",
      "Tokenization...(should take about 30 seconds)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from util.preprocessing_qg import tokenize\n",
    "\n",
    "train_df = tokenize(train_df)\n",
    "val_df = tokenize(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6cd2b6",
   "metadata": {
    "id": "eb199b2d"
   },
   "source": [
    "## Fix answers' position\n",
    "\n",
    "Answers are provided in the form of (char_start, char_end) with respect to the original context, however:\n",
    "- After tokenization, **characters** have no meaning anymore, since we deal with words\n",
    "  - Thus, we convert characters to **word indices**\n",
    "- Tokenization splits long contexts (according to the parameter `max_length`), which results in some context splits not containing the answer.\n",
    "  - To address this problem, we assign `answer_start, answer_end = (0,0)` whenever the answer is neither partially nor fully contained within the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a105a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:00:02.740213Z",
     "start_time": "2022-02-01T16:59:39.702880Z"
    }
   },
   "outputs": [],
   "source": [
    "from util.preprocessing_qg import fix_answers\n",
    "\n",
    "fix_answers(train_df)\n",
    "fix_answers(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd4970",
   "metadata": {
    "id": "0efbc431"
   },
   "source": [
    "## Save\n",
    "\n",
    "- Allow for one-hot encoding of answers (which however seems not useful, as both the loss function (`torch.CrossEntropyLoss`) and the evaluation metrics (`torchmetrics.F1Score`, `torchmetrics.Accuracy`, `torchmetrics.AveragePrecision`) accept targets as 1D.\n",
    "- Save data as a compressed `.npz` archive for later retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e7de2",
   "metadata": {
    "id": "fnTP7V3LFuHn"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding for answers\n",
    "one_hot = False\n",
    "if one_hot:\n",
    "    from util.preprocessing import one_hot_answers\n",
    "    oh_data = one_hot_answers(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c216557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:03:00.646485Z",
     "start_time": "2022-02-01T17:02:07.576529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save integer data\n",
    "keys = [item for item in list(train_df.columns) if item != 'id']\n",
    "train_data = {key:np.stack(train_df[key]).astype('int32') for key in keys}\n",
    "val_data = {key:np.stack(val_df[key]).astype('int32') for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc26570a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:03:11.294745Z",
     "start_time": "2022-02-01T17:03:11.172948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save id (string)\n",
    "train_data['id'] = train_df['id'].values.astype(np.unicode_)\n",
    "val_data['id'] = val_df['id'].values.astype(np.unicode_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf767e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:04:05.196942Z",
     "start_time": "2022-02-01T17:03:54.207302Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./data/tokenized-qg/train.npz', **train_data)\n",
    "np.savez_compressed('./data/tokenized-qg/val.npz', **val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17583070",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "\n",
    "- Check data was correctly saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2377ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T17:04:24.861910Z",
     "start_time": "2022-02-01T17:04:20.638571Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_saved = np.load('./data/tokenized-qg/train.npz')\n",
    "val_data_saved = np.load('./data/tokenized-qg/val.npz')\n",
    "\n",
    "for key in keys:\n",
    "    assert np.equal(train_data[key], train_data_saved[key]).all()\n",
    "    assert np.equal(val_data[key], val_data_saved[key]).all()\n",
    "    \n",
    "assert (np.char.strip(train_data['id']) == np.char.strip(train_data_saved['id'])).all()\n",
    "assert (np.char.strip(val_data['id']) == np.char.strip(val_data_saved['id'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67262d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "QA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
