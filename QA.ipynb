{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c69e289",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "291d7474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T17:53:45.179473Z",
     "start_time": "2022-01-04T17:53:45.101515Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90611bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T16:37:48.876107Z",
     "start_time": "2022-01-04T16:37:34.021947Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a042c31f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T16:36:41.431946Z",
     "start_time": "2022-01-04T16:36:41.378021Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa58304",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3124ea1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T18:25:38.678408Z",
     "start_time": "2021-12-28T18:25:37.388290Z"
    }
   },
   "outputs": [],
   "source": [
    "#from read_dataset import read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a5509a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T18:25:40.480885Z",
     "start_time": "2021-12-28T18:25:39.240526Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataset = read_dataset(path='SQUAD MATERIAL/training_set.json', validation_set_perc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd029bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T18:25:50.580299Z",
     "start_time": "2021-12-28T18:25:47.980402Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_df = pd.DataFrame(dataset[0], columns=['id', 'title', 'context', 'question', 'start', 'end'])\n",
    "#train_df.to_csv('./data/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d675f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T18:25:52.435022Z",
     "start_time": "2021-12-28T18:25:51.703043Z"
    }
   },
   "outputs": [],
   "source": [
    "#val_df = pd.DataFrame(dataset[1], columns=['id', 'title', 'context', 'question', 'start', 'end'])\n",
    "#val_df.to_csv('./data/val_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a453903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T16:37:29.578980Z",
     "start_time": "2022-01-04T16:37:28.611162Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train_df.csv')\n",
    "val_df = pd.read_csv('./data/val_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c7b87",
   "metadata": {},
   "source": [
    "### Read questions and contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4421e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T16:37:31.515879Z",
     "start_time": "2022-01-04T16:37:31.480418Z"
    }
   },
   "outputs": [],
   "source": [
    "questions = list(train_df['question'].values)\n",
    "contexts = list(train_df['context'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd6f886",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "862509a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T17:23:02.618090Z",
     "start_time": "2022-01-04T17:22:54.915789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased-distilled-squad were not used when initializing DistilBertModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and transformers\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased-distilled-squad')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-cased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a0fdafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T16:49:27.772624Z",
     "start_time": "2022-01-04T16:49:27.670794Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Tokenize questions and contexts\n",
    "max_length = model.config.max_position_embeddings\n",
    "doc_stride = 128\n",
    "\n",
    "#tokenized = tokenizer(\n",
    "#    questions[:10],\n",
    "#    contexts[:10],\n",
    "#    max_length=max_length,\n",
    "#    truncation=\"only_second\",\n",
    "#    return_overflowing_tokens=True,\n",
    "#    return_offsets_mapping=True,\n",
    "#    stride=doc_stride,\n",
    "#    return_attention_mask=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf948d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd5836ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:23:09.025496Z",
     "start_time": "2021-12-23T17:23:08.944964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f663b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T16:49:32.258405Z",
     "start_time": "2022-01-04T16:49:32.173144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 2),\n",
       " (3, 7),\n",
       " (8, 11),\n",
       " (12, 15),\n",
       " (16, 22),\n",
       " (23, 27),\n",
       " (28, 37),\n",
       " (38, 44),\n",
       " (45, 47),\n",
       " (48, 52),\n",
       " (53, 55),\n",
       " (56, 59),\n",
       " (59, 63),\n",
       " (64, 70),\n",
       " (70, 71),\n",
       " (0, 0),\n",
       " (0, 13),\n",
       " (13, 15),\n",
       " (15, 16),\n",
       " (17, 20),\n",
       " (21, 27),\n",
       " (28, 31),\n",
       " (32, 33),\n",
       " (34, 42),\n",
       " (43, 52),\n",
       " (52, 53),\n",
       " (54, 56),\n",
       " (56, 58),\n",
       " (59, 62),\n",
       " (63, 67),\n",
       " (68, 76),\n",
       " (76, 77),\n",
       " (77, 78),\n",
       " (79, 83),\n",
       " (84, 88),\n",
       " (89, 91),\n",
       " (92, 93),\n",
       " (94, 100),\n",
       " (101, 107),\n",
       " (108, 110),\n",
       " (111, 114),\n",
       " (115, 121),\n",
       " (122, 126),\n",
       " (126, 127),\n",
       " (128, 139),\n",
       " (140, 142),\n",
       " (143, 148),\n",
       " (149, 151),\n",
       " (152, 155),\n",
       " (156, 160),\n",
       " (161, 169),\n",
       " (170, 173),\n",
       " (174, 180),\n",
       " (181, 183),\n",
       " (183, 184),\n",
       " (185, 187),\n",
       " (188, 189),\n",
       " (190, 196),\n",
       " (197, 203),\n",
       " (204, 206),\n",
       " (207, 213),\n",
       " (214, 218),\n",
       " (219, 223),\n",
       " (224, 226),\n",
       " (226, 229),\n",
       " (229, 232),\n",
       " (233, 237),\n",
       " (238, 241),\n",
       " (242, 248),\n",
       " (249, 250),\n",
       " (250, 251),\n",
       " (251, 254),\n",
       " (254, 256),\n",
       " (257, 259),\n",
       " (260, 262),\n",
       " (263, 264),\n",
       " (264, 265),\n",
       " (265, 268),\n",
       " (268, 269),\n",
       " (269, 270),\n",
       " (271, 275),\n",
       " (276, 278),\n",
       " (279, 282),\n",
       " (283, 287),\n",
       " (288, 296),\n",
       " (297, 299),\n",
       " (300, 303),\n",
       " (304, 312),\n",
       " (313, 315),\n",
       " (316, 319),\n",
       " (320, 326),\n",
       " (327, 332),\n",
       " (332, 333),\n",
       " (334, 345),\n",
       " (346, 352),\n",
       " (353, 356),\n",
       " (357, 358),\n",
       " (358, 361),\n",
       " (361, 365),\n",
       " (366, 368),\n",
       " (369, 372),\n",
       " (373, 374),\n",
       " (374, 377),\n",
       " (377, 379),\n",
       " (379, 380),\n",
       " (381, 382),\n",
       " (383, 389),\n",
       " (390, 395),\n",
       " (396, 398),\n",
       " (399, 405),\n",
       " (406, 409),\n",
       " (410, 420),\n",
       " (420, 421),\n",
       " (422, 424),\n",
       " (425, 427),\n",
       " (428, 429),\n",
       " (430, 437),\n",
       " (438, 440),\n",
       " (441, 444),\n",
       " (445, 446),\n",
       " (446, 449),\n",
       " (449, 451),\n",
       " (452, 454),\n",
       " (455, 458),\n",
       " (458, 462),\n",
       " (462, 463),\n",
       " (464, 470),\n",
       " (471, 476),\n",
       " (477, 480),\n",
       " (481, 487),\n",
       " (488, 492),\n",
       " (493, 500),\n",
       " (500, 502),\n",
       " (503, 511),\n",
       " (512, 514),\n",
       " (515, 520),\n",
       " (521, 525),\n",
       " (525, 528),\n",
       " (528, 531),\n",
       " (532, 534),\n",
       " (534, 537),\n",
       " (537, 541),\n",
       " (542, 544),\n",
       " (545, 549),\n",
       " (549, 550),\n",
       " (551, 553),\n",
       " (554, 557),\n",
       " (558, 561),\n",
       " (562, 564),\n",
       " (565, 568),\n",
       " (569, 573),\n",
       " (574, 579),\n",
       " (580, 581),\n",
       " (581, 584),\n",
       " (585, 587),\n",
       " (588, 589),\n",
       " (590, 596),\n",
       " (597, 601),\n",
       " (602, 606),\n",
       " (607, 615),\n",
       " (616, 623),\n",
       " (624, 625),\n",
       " (626, 633),\n",
       " (634, 637),\n",
       " (638, 641),\n",
       " (642, 646),\n",
       " (647, 651),\n",
       " (651, 652),\n",
       " (652, 653),\n",
       " (654, 656),\n",
       " (657, 658),\n",
       " (659, 665),\n",
       " (665, 666),\n",
       " (667, 673),\n",
       " (674, 679),\n",
       " (680, 686),\n",
       " (687, 689),\n",
       " (690, 694),\n",
       " (694, 695),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized['offset_mapping'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e323107",
   "metadata": {},
   "source": [
    "`tokenized['offset_mapping'][0]` returna le tuple (start,end) di ogni parola dell'input (query, context)\n",
    "Problema: risposte si accavallano attorno a max_length\n",
    "Soluzione: riscalare tuple di contesti tagliati (invece che 0, allinearli alla risposta)\n",
    "[soluzione](https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/question_answering.ipynb#scrollTo=iLekL6Un9D70&line=24&uniqifier=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4d22e",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "- creare dataframe con contesti splittati (lunghezza 512, overlapping 256)\n",
    "    - riscalare answer_start e answer_end per ogni contesto\n",
    "    - lo split che contiene la risposta mantiene answer_start e answer_end, gli altri split dello stesso contesto vanno trattati (assegniamo (0,0)? oppure scartiamo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "450abd9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T18:03:41.110836Z",
     "start_time": "2022-01-04T18:03:41.026661Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized = tokenizer(\n",
    "    questions[:10],\n",
    "    contexts[:10],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=doc_stride,\n",
    "    return_attention_mask=True,\n",
    "    padding='max_length'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04a525d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T17:38:27.953037Z",
     "start_time": "2022-01-04T17:38:27.765928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['question'].apply(lambda x: len(x.strip().split(' '))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6bb783c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T17:54:02.788801Z",
     "start_time": "2022-01-04T17:54:02.637340Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5651db04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T18:03:49.247038Z",
     "start_time": "2022-01-04T18:03:49.180148Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_dict = {}\n",
    "\n",
    "bert_dict['input_ids'] = torch.IntTensor(tokenized['input_ids']).to(device)\n",
    "bert_dict['attention_mask'] = torch.IntTensor(tokenized['attention_mask']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f6c70c7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T18:04:00.186601Z",
     "start_time": "2022-01-04T18:03:49.937672Z"
    }
   },
   "outputs": [],
   "source": [
    "transformed = model(**bert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b1eb0b9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T18:04:04.576457Z",
     "start_time": "2022-01-04T18:04:04.481599Z"
    }
   },
   "outputs": [],
   "source": [
    "dropped = torch.nn.Dropout(0.3)(transformed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "79c6923e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T18:04:05.522098Z",
     "start_time": "2022-01-04T18:04:05.454172Z"
    }
   },
   "outputs": [],
   "source": [
    "logits = torch.nn.Linear(768, 2)(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c9ce5299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T18:04:07.485105Z",
     "start_time": "2022-01-04T18:04:07.410693Z"
    }
   },
   "outputs": [],
   "source": [
    "start_logits, end_logits = logits.split(1, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "98959e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T18:04:10.568711Z",
     "start_time": "2022-01-04T18:04:10.497015Z"
    }
   },
   "outputs": [],
   "source": [
    "start_logits = start_logits.squeeze(-1)\n",
    "end_logits = end_logits.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f40eade1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T18:04:11.374580Z",
     "start_time": "2022-01-04T18:04:11.236384Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = (start_logits, end_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205600e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-04T17:10:05.826417Z",
     "start_time": "2022-01-04T17:10:05.741367Z"
    }
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=768, num_labels=2, dropout_rate=0.5):\n",
    "        super(QA, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        self.tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased-distilled-squad')\n",
    "        self.model = DistilBertModel.from_pretrained('distilbert-base-cased-distilled-squad')\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        #self.extra_linear = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        #self.extra_linear_tanh = torch.nn.Tanh()\n",
    "        self.dense = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Unpack inputs\n",
    "        questions, contexts = inputs\n",
    "        # Tokenizer\n",
    "        tokenized = self.tokenizer(\n",
    "            questions,\n",
    "            contexts,\n",
    "            max_length=max_length,\n",
    "            truncation=\"only_second\",\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            stride=doc_stride,\n",
    "            return_attention_mask=True,\n",
    "            padding='max_length'\n",
    "        )\n",
    "        # Put to device\n",
    "        bert_dict = {}\n",
    "\n",
    "        bert_dict['input_ids'] = torch.IntTensor(tokenized['input_ids']).to(self.device)\n",
    "        bert_dict['attention_mask'] = torch.IntTensor(tokenized['attention_mask']).to(self.device)\n",
    "        # Transformers \n",
    "        transformed = self.model(**bert_dict)\n",
    "        # Dropout\n",
    "        dropped = self.dropout(transformed[0])\n",
    "        # Obtain logits\n",
    "        logits = self.dense(dropped) #(None, seq_len, hidden_size)*(hidden_size, 2)=(None, seq_len, 2)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)    #(None, seq_len, 1), (None, seq_len, 1)\n",
    "        start_logits = start_logits.squeeze(-1)  #(None, seq_len)\n",
    "        end_logits = end_logits.squeeze(-1)    #(None, seq_len)\n",
    "        # --- 4) Prepare output tuple\n",
    "        outputs = (start_logits, end_logits)\n",
    "        \n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
