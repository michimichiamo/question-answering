{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c69e289",
      "metadata": {
        "id": "3c69e289"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "291d7474",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T12:46:05.154416Z",
          "start_time": "2022-01-12T12:45:57.538962Z"
        },
        "id": "291d7474"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Suppress output\n",
        "\n",
        "# Whether the notebook is run within Google Colab or not\n",
        "colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "# General imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "# Install needed dependencies on Colab\n",
        "if colab:\n",
        "    !pip install transformers\n",
        "    !pip install torchmetrics\n",
        "from transformers import DistilBertModel#, DistilBertTokenizerFast\n",
        "\n",
        "# Enable GPU acceleration, whenever available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Automatically reimport modules at each execution\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "86992ec3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T12:46:05.223020Z",
          "start_time": "2022-01-12T12:46:05.157398Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86992ec3",
        "outputId": "d791ce50-e6d3-427c-8a57-aee9f8d5794f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'question-answering' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "if colab:\n",
        "    !git clone 'https://github.com/michimichiamo/question-answering'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaa58304",
      "metadata": {
        "id": "eaa58304"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3124ea1c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T12:46:05.281868Z",
          "start_time": "2022-01-12T12:46:05.226393Z"
        },
        "id": "3124ea1c"
      },
      "outputs": [],
      "source": [
        "# Execute this only to load the dataset in csv format if not already done\n",
        "# from read_dataset import read_dataset\n",
        "\n",
        "# dataset = read_dataset(path='training_set.json', validation_set_perc=20)\n",
        "# train_df = pd.DataFrame(dataset[0], columns=['id', 'title', 'context_id', 'context', 'question', 'start', 'end'])\n",
        "# train_df.to_csv('train_df.csv')\n",
        "# val_df = pd.DataFrame(dataset[1], columns=['id', 'title', 'context_id', 'context', 'question', 'start', 'end'])\n",
        "# val_df.to_csv('val_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6fb334c6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T12:46:05.344966Z",
          "start_time": "2022-01-12T12:46:05.284455Z"
        },
        "id": "6fb334c6"
      },
      "outputs": [],
      "source": [
        "directory='./' if not colab else './question-answering/'\n",
        "\n",
        "train_filename = directory+'data/tokenized/train.npz'\n",
        "val_filename = directory+'data/tokenized/val.npz'\n",
        "\n",
        "train_data = np.load(train_filename)\n",
        "val_data = np.load(val_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6b01bd4b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T12:46:07.116897Z",
          "start_time": "2022-01-12T12:46:05.347475Z"
        },
        "id": "6b01bd4b"
      },
      "outputs": [],
      "source": [
        "train_input_ids = train_data['input_ids'].astype('int32')\n",
        "train_attention_mask = train_data['attention_mask'].astype('int32')\n",
        "train_answer_start = train_data['answer_start'].astype('int32')\n",
        "train_answer_end = train_data['answer_end'].astype('int32')\n",
        "\n",
        "val_input_ids = val_data['input_ids'].astype('int32')\n",
        "val_attention_mask = val_data['attention_mask'].astype('int32')\n",
        "val_answer_start = val_data['answer_start'].astype('int32')\n",
        "val_answer_end = val_data['answer_end'].astype('int32')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6205600e",
      "metadata": {
        "id": "6205600e"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4916e6fc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T12:46:07.652998Z",
          "start_time": "2022-01-12T12:46:07.593116Z"
        },
        "id": "4916e6fc"
      },
      "outputs": [],
      "source": [
        "class QA(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size=768, num_labels=2, dropout_rate=0.5):\n",
        "        super(QA, self).__init__()\n",
        "        # Device\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        \n",
        "        # Parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_labels = num_labels\n",
        "        \n",
        "        # Layers\n",
        "        #self.tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased-distilled-squad')\n",
        "        self.transformers = DistilBertModel.from_pretrained('distilbert-base-cased-distilled-squad').to(self.device)\n",
        "        self.transformers.requires_grad_(False)\n",
        "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
        "        #self.extra_linear = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        #self.extra_linear_tanh = torch.nn.Tanh()\n",
        "        self.dense = torch.nn.Linear(self.hidden_size, self.num_labels, device=self.device, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Unpack inputs\n",
        "        input_ids, attention_mask = inputs\n",
        "        \n",
        "        # Put to device\n",
        "        input_ids = input_ids.to(self.device)\n",
        "        attention_mask = attention_mask.to(self.device)\n",
        "        \n",
        "        # Transformers \n",
        "        transformed = self.transformers(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # Dropout\n",
        "        dropped = self.dropout(transformed[0])\n",
        "        # Obtain logits\n",
        "        logits = self.dense(dropped) #(None, seq_len, hidden_size)*(hidden_size, 2)=(None, seq_len, 2)\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)    #(None, seq_len, 1), (None, seq_len, 1)\n",
        "        start_logits = start_logits.squeeze(-1)  #(None, seq_len)\n",
        "        end_logits = end_logits.squeeze(-1)    #(None, seq_len)\n",
        "        # --- 4) Prepare output tuple\n",
        "        outputs = (start_logits, end_logits)\n",
        "        \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ZX7lp9lGApN4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T12:46:10.864157Z",
          "start_time": "2022-01-12T12:46:10.798299Z"
        },
        "id": "ZX7lp9lGApN4"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, input_ids, attention_masks, answer_starts, answer_ends):\n",
        "        'Initialization'\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.answer_starts = answer_starts\n",
        "        self.answer_ends = answer_ends\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        input_id = self.input_ids[index]\n",
        "        attention_mask = self.attention_masks[index]\n",
        "        answer_start = self.answer_starts[index]\n",
        "        answer_end = self.answer_ends[index]\n",
        "\n",
        "        # Pack input and output\n",
        "        X = (input_id, attention_mask)\n",
        "        y = (answer_start, answer_end)\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hyperparameters\n",
        "batch_size = 256 #@param [\"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "learning_rate = 0.001 #@param [\"0.00001\", \"0.0001\", \"0.001\", \"0.01\", \"0.1\", \"1\"] {type:\"raw\"}\n",
        "epochs = 5 #@param {type:\"slider\", min:5, max:200, step:5}\n"
      ],
      "metadata": {
        "id": "SFKL9c4TZSa3"
      },
      "id": "SFKL9c4TZSa3",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "QqhlR1A9BKsa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T12:46:10.924544Z",
          "start_time": "2022-01-12T12:46:10.866537Z"
        },
        "id": "QqhlR1A9BKsa"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_input_ids, train_attention_mask, train_answer_start, train_answer_end)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)#, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = Dataset(val_input_ids, val_attention_mask, val_answer_start, val_answer_end)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, )#, num_workers=2, pin_memory=True)\n",
        "val_dataloader = iter(val_dataloader)"
      ],
      "metadata": {
        "id": "arGKmyRmXSlB"
      },
      "id": "arGKmyRmXSlB",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del train_input_ids, train_attention_mask, train_answer_start, train_answer_end\n",
        "del val_input_ids, val_attention_mask, val_answer_start, val_answer_end\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-ME4IcRMhb2",
        "outputId": "568fb98e-e222-4f7b-bd72-b3982bac428e"
      },
      "id": "R-ME4IcRMhb2",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "437"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "# Create model\n",
        "net = QA()\n",
        "net.to(net.device)\n",
        "optimizer = Adam(net.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "loss_fn = CrossEntropyLoss()\n",
        "n_iter = len(train_dataloader)"
      ],
      "metadata": {
        "id": "IZpQ_Tn6PnTC"
      },
      "id": "IZpQ_Tn6PnTC",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import AveragePrecision, F1\n",
        "\n",
        "# Define scores and send to device\n",
        "f1_score = F1(num_classes=net.transformers.config.max_position_embeddings, mdmc_average='global')\n",
        "f1_score = f1_score.to(device)\n",
        "average_precision = AveragePrecision(pos_label=1, num_classes=net.transformers.config.max_position_embeddings)\n",
        "average_precision = average_precision.to(device)\n",
        "\n",
        "def evaluate(model, inputs, targets):\n",
        "    # Set evaluation mode\n",
        "    model.eval()\n",
        "    # Obtain predictions\n",
        "    start_preds, end_preds = model.forward(inputs)\n",
        "    # Unpack targets and send to device\n",
        "    start_logits, end_logits = targets\n",
        "    start_logits = start_logits.to(model.device)\n",
        "    end_logits = end_logits.to(model.device)\n",
        "    \n",
        "    # Extract IntTensors for predictions\n",
        "    start_out, end_out = torch.zeros_like(start_preds, dtype=torch.int16), torch.zeros_like(end_preds, dtype=torch.int16)\n",
        "    start_out[torch.tensor(range(start_preds.size()[0])), torch.argmax(start_preds, axis=1)] = 1\n",
        "    end_out[torch.tensor(range(end_preds.size()[0])), torch.argmax(end_preds, axis=1)] = 1\n",
        "\n",
        "    # Send predictions to device\n",
        "    start_out.to(model.device)\n",
        "    end_out.to(model.device)\n",
        "\n",
        "    # Get F1 scores\n",
        "    f1_start = f1_score(start_out, start_logits)\n",
        "    f1_end = f1_score(end_out, end_logits)\n",
        "    f1 = f1_start + f1_end\n",
        "    \n",
        "    # Get Average Precision scores\n",
        "    avg_start = average_precision(start_out, torch.argmax(start_logits, axis=1))\n",
        "    avg_end = average_precision(end_out, torch.argmax(end_logits, axis=1))\n",
        "    avg = avg_start + avg_end\n",
        "\n",
        "    print(f'f1 score: {f1:.10f}')\n",
        "    print(f'average precision: {avg:.5f}')\n",
        "    return f1.to('cpu'), avg.to('cpu')\n"
      ],
      "metadata": {
        "id": "Wiv72WDyWXvC",
        "outputId": "4a8da8cc-996e-4759-a360-dd9d61dbf334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Wiv72WDyWXvC",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dhvSBZ549wLG",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-12T14:39:15.485889Z",
          "start_time": "2022-01-12T12:46:11.068018Z"
        },
        "id": "dhvSBZ549wLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6e1b3b-ded6-4216-85e1-f1c45cbe51ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1/279\n",
            "loss = 29912.259765625\n",
            "iteration 2/279\n",
            "loss = 31603.671875\n",
            "iteration 3/279\n",
            "loss = 33131.4375\n",
            "iteration 4/279\n",
            "loss = 34167.171875\n",
            "iteration 5/279\n",
            "loss = 34488.984375\n",
            "iteration 6/279\n",
            "loss = 34727.34375\n",
            "iteration 7/279\n",
            "loss = 34412.609375\n",
            "iteration 8/279\n",
            "loss = 33819.7578125\n",
            "iteration 9/279\n",
            "loss = 32863.3515625\n",
            "iteration 10/279\n",
            "loss = 31913.689453125\n",
            "iteration 11/279\n",
            "loss = 31761.21484375\n",
            "iteration 12/279\n",
            "loss = 29656.669921875\n",
            "iteration 13/279\n",
            "loss = 27884.515625\n",
            "iteration 14/279\n",
            "loss = 26655.009765625\n",
            "iteration 15/279\n",
            "loss = 25003.44921875\n",
            "iteration 16/279\n",
            "loss = 23199.79296875\n",
            "iteration 17/279\n",
            "loss = 21093.71484375\n",
            "iteration 18/279\n",
            "loss = 19247.255859375\n",
            "iteration 19/279\n",
            "loss = 16783.80859375\n",
            "iteration 20/279\n",
            "loss = 15065.560546875\n",
            "iteration 21/279\n",
            "loss = 12711.82421875\n",
            "iteration 22/279\n",
            "loss = 10398.6611328125\n",
            "iteration 23/279\n",
            "loss = 8013.0009765625\n",
            "iteration 24/279\n",
            "loss = 6092.8623046875\n",
            "iteration 25/279\n",
            "loss = 3659.595947265625\n",
            "iteration 26/279\n",
            "loss = 1361.5079345703125\n",
            "iteration 27/279\n",
            "loss = -1114.907958984375\n",
            "iteration 28/279\n",
            "loss = -3934.68701171875\n",
            "iteration 29/279\n",
            "loss = -6457.63916015625\n",
            "iteration 30/279\n",
            "loss = -8720.15625\n",
            "iteration 31/279\n",
            "loss = -11107.81640625\n",
            "iteration 32/279\n",
            "loss = -13561.337890625\n",
            "iteration 33/279\n",
            "loss = -16102.6162109375\n",
            "iteration 34/279\n",
            "loss = -18595.119140625\n",
            "iteration 35/279\n",
            "loss = -20824.9765625\n",
            "iteration 36/279\n",
            "loss = -23649.2421875\n",
            "iteration 37/279\n",
            "loss = -26597.212890625\n",
            "iteration 38/279\n",
            "loss = -29168.677734375\n",
            "iteration 39/279\n",
            "loss = -31725.75390625\n",
            "iteration 40/279\n",
            "loss = -34261.52734375\n",
            "iteration 41/279\n",
            "loss = -36832.37109375\n",
            "iteration 42/279\n",
            "loss = -39835.8984375\n",
            "iteration 43/279\n",
            "loss = -42468.453125\n",
            "iteration 44/279\n",
            "loss = -45314.33984375\n",
            "iteration 45/279\n",
            "loss = -47685.3828125\n",
            "iteration 46/279\n",
            "loss = -50203.40625\n",
            "iteration 47/279\n",
            "loss = -53001.5078125\n",
            "iteration 48/279\n",
            "loss = -55613.8515625\n",
            "iteration 49/279\n"
          ]
        }
      ],
      "source": [
        "loss_history = []\n",
        "f1_history = []\n",
        "avg_prec_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    net.train()\n",
        "    for iteration, (train_inputs, train_targets) in enumerate(train_dataloader):\n",
        "        net.train()\n",
        "        # Unpack targets and cast to float\n",
        "        start_logits, end_logits = train_targets\n",
        "        start_logits, end_logits = torch.tensor(start_logits, dtype=torch.float32, device=device), torch.tensor(end_logits, dtype=torch.float32, device=device)\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        start_out, end_out = net.forward(train_inputs)\n",
        "        # Loss function\n",
        "        ## TOCHECK\n",
        "        loss = loss_fn(start_logits, start_out) +loss_fn(end_logits, end_out)\n",
        "        # Gradient update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "#\n",
        "        # Track loss\n",
        "        print(f'iteration {iteration+1}/{n_iter}')\n",
        "        print(f'loss = {loss}')\n",
        "        loss_history.append(loss)\n",
        "    \n",
        "    #if epoch % 5 == 0:\n",
        "    net.eval()\n",
        "    val_inputs, val_targets = next(val_dataloader)\n",
        "    f1, avg_prec = evaluate(net, val_inputs, val_targets)\n",
        "    f1_history.append(f1)\n",
        "    avg_prec_history.append(avg_prec)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OK4tFfSgF2c3"
      },
      "id": "OK4tFfSgF2c3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "QA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:root] *",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}